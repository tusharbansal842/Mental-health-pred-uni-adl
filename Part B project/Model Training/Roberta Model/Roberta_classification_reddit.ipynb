{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0723a37d-61e9-405d-8e4c-22c22bddd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ae0840-3f64-46ea-baf2-fcb0cf218b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=28, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"../Roberta/best_roberta_finetuned\"\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()  # put model in evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83029bf7-2d0b-46ad-b784-3a43a3196c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 95250 posts for prediction.\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../Data for analysis/data_for_further_analysis.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Combine title + clean_text (if available) for prediction input\n",
    "if {'title', 'clean_text'}.issubset(df.columns):\n",
    "    df[\"post\"] = df[\"title\"].fillna('') + \" \" + df[\"clean_text\"].fillna('')\n",
    "elif \"clean_text\" in df.columns:\n",
    "    df[\"post\"] = df[\"clean_text\"].fillna('')\n",
    "else:\n",
    "    raise ValueError(\"Expected columns 'title' and/or 'clean_text' not found in dataset.\")\n",
    "\n",
    "texts = df[\"post\"].tolist()\n",
    "print(f\"✅ Loaded {len(texts)} posts for prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08bb6135-8645-48cc-af8f-3555934e4a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5954/5954 [02:17<00:00, 43.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predictions with probabilities saved to: ../Roberta/Output/predictions_with_probs.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# --- GoEmotions label set ---\n",
    "goemotions_labels = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
    "    \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
    "    \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\",\n",
    "    \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\",\n",
    "    \"realization\", \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "# --- Prediction function (returns probs + labels) ---\n",
    "def predict_with_probs(text_list, model, tokenizer, batch_size=16):\n",
    "    all_preds, all_probs = [], []\n",
    "    for i in tqdm(range(0, len(text_list), batch_size), desc=\"Predicting\"):\n",
    "        batch_texts = text_list[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True,\n",
    "                           padding=True, max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(probs, dim=-1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_probs)\n",
    "\n",
    "# --- Run predictions ---\n",
    "pred_labels, pred_probs = predict_with_probs(df[\"post\"].tolist(), model, tokenizer)\n",
    "\n",
    "# --- Convert to readable format ---\n",
    "df[\"predicted_label_id\"] = pred_labels\n",
    "df[\"predicted_emotion\"] = [goemotions_labels[i] for i in pred_labels]\n",
    "\n",
    "# Add top 3 emotions per post if you want:\n",
    "top3 = np.argsort(-pred_probs, axis=1)[:, :3]\n",
    "df[\"top3_emotions\"] = [\n",
    "    \", \".join([goemotions_labels[j] for j in row]) for row in top3\n",
    "]\n",
    "\n",
    "# --- Add probabilities as columns (optional, large but detailed) ---\n",
    "for i, label in enumerate(goemotions_labels):\n",
    "    df[f\"prob_{label}\"] = pred_probs[:, i]\n",
    "\n",
    "# --- Keep only relevant columns for output ---\n",
    "final_df = df[[\"subreddit\", \"post\", \"predicted_emotion\", \"top3_emotions\"] + [f\"prob_{l}\" for l in goemotions_labels]]\n",
    "\n",
    "# --- Save results ---\n",
    "output_path = \"../Roberta/Output/predictions_with_probs.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Predictions with probabilities saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
