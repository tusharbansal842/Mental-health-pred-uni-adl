{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae5caa8-4940-44b8-a785-8ecfcb892426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets transformers torch scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f916fea-86e0-46cc-97bc-f017f8398394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade accelerate transformers torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2f5754-8e10-4d1a-af9e-70bb15cd85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U datasets transformers accelerate torch torchvision torchaudio scikit-learn tqdm pandas numpy matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13733a00-5105-4b4a-b041-67101bafaa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.0\n",
      "Transformers: 4.57.1\n",
      "Datasets: 4.2.0\n",
      "scikit-learn: 1.7.2\n",
      "CUDA available: False\n",
      "MPS available (Apple GPU): True\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers, datasets, sklearn\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Datasets:\", datasets.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"MPS available (Apple GPU):\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50bf613-b3df-4d04-a886-8a903119806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e990253d-300a-45a0-bc1e-616c3b59da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 43410\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 5426\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 5427\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset directly from Hugging Face\n",
    "goemotions = load_dataset(\"go_emotions\")\n",
    "\n",
    "# Inspect available splits\n",
    "print(goemotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ae78746-53d7-4a57-a3be-103f3283b9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train+validation samples: 48836\n",
      "Test samples: 5427\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "goemotions_combined = concatenate_datasets([goemotions[\"train\"], goemotions[\"validation\"]])\n",
    "print(f\"Combined train+validation samples: {len(goemotions_combined)}\")\n",
    "print(f\"Test samples: {len(goemotions['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b4d25b-9976-48b7-be4b-8f4a2a285fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labels: 28\n",
      "Example labels: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels       id\n",
       "0  My favourite food is anything I didn't have to...   [27]  eebbqej\n",
       "1  Now if he does off himself, everyone will thin...   [27]  ed00q6i\n",
       "2                     WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj\n",
       "3                        To make her feel threatened   [14]  ed7ypvh\n",
       "4                             Dirty Southern Wankers    [3]  ed0bdzj"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = goemotions_combined.to_pandas()\n",
    "\n",
    "# Extract label names from the original GoEmotions schema\n",
    "labels = goemotions[\"train\"].features[\"labels\"].feature.names\n",
    "print(\"Total labels:\", len(labels))\n",
    "print(\"Example labels:\", labels[:10])\n",
    "\n",
    "# Display sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c586dd-1387-4bc0-a22e-7a6ac8b6b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_label\n",
       "27    14415\n",
       "0      4618\n",
       "4      2951\n",
       "1      2541\n",
       "15     2393\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simplify each sample to its first label for single-label classification\n",
    "df[\"main_label\"] = df[\"labels\"].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "df = df.dropna(subset=[\"main_label\"])\n",
    "df = df.rename(columns={\"text\": \"content\"})\n",
    "\n",
    "# View distribution\n",
    "df[\"main_label\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c189dea8-f0ca-4f10-9c82-d4d94272a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, val_df = train_test_split(\n",
    "#     df,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=df[\"main_label\"]\n",
    "# )\n",
    "\n",
    "# print(f\"Train: {len(train_df)}, Validation: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74327bd7-3033-46ca-b46a-bf91e148b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train samples: 48836, Validation/Test samples: 5427\n"
     ]
    }
   ],
   "source": [
    "train_df = df.copy()                      \n",
    "val_df = goemotions[\"test\"].to_pandas()   \n",
    "\n",
    "print(f\" Train samples: {len(train_df)}, Validation/Test samples: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b41ec43-4661-4282-94ca-f3f887a0e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"SamLowe/roberta-base-go_emotions\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b897a5a-1baa-4772-b7ef-0d8f8a6e056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d66396-5efa-49ae-a665-4abae777c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"text\" in val_df.columns and \"content\" not in val_df.columns:\n",
    "    val_df = val_df.rename(columns={\"text\": \"content\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16fe372-ec83-4944-bc03-65071dbd07a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_id</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I‚Äôm really sorry about your situation :( Altho...</td>\n",
       "      <td>[25]</td>\n",
       "      <td>eecwqtt</td>\n",
       "      <td>24</td>\n",
       "      <td>remorse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>[0]</td>\n",
       "      <td>ed5f85d</td>\n",
       "      <td>0</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>[13]</td>\n",
       "      <td>een27c3</td>\n",
       "      <td>20</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>eelgwd1</td>\n",
       "      <td>15</td>\n",
       "      <td>gratitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eem5uti</td>\n",
       "      <td>27</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content labels       id  \\\n",
       "0  I‚Äôm really sorry about your situation :( Altho...   [25]  eecwqtt   \n",
       "1    It's wonderful because it's awful. At not with.    [0]  ed5f85d   \n",
       "2  Kings fan here, good luck to you guys! Will be...   [13]  een27c3   \n",
       "3  I didn't know that, thank you for teaching me ...   [15]  eelgwd1   \n",
       "4  They got bored from haunting earth for thousan...   [27]  eem5uti   \n",
       "\n",
       "   predicted_id predicted_label  \n",
       "0            24         remorse  \n",
       "1             0      admiration  \n",
       "2            20        optimism  \n",
       "3            15       gratitude  \n",
       "4            27         neutral  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert validation texts to list\n",
    "val_texts = val_df[\"content\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "batch_size = 32\n",
    "all_pred_ids = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(val_texts), batch_size):\n",
    "        batch_texts = val_texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        logits = model(**enc).logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_pred_ids.extend(preds.cpu().tolist())\n",
    "\n",
    "# Map IDs to label names\n",
    "id2label = model.config.id2label\n",
    "predicted_labels = [id2label[int(i)] for i in all_pred_ids]\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "val_df[\"predicted_id\"] = all_pred_ids\n",
    "val_df[\"predicted_label\"] = predicted_labels\n",
    "\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e9a5949-c03f-4eb1-b35d-8da46c27c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"main_label\" not in val_df.columns:\n",
    "    # Each test sample's 'labels' field is a list ‚Üí extract first label like we did for training\n",
    "    val_df[\"main_label\"] = val_df[\"labels\"].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
    "    val_df = val_df.dropna(subset=[\"main_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe1d9f84-b123-49f3-bd3f-79c36f94ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tusharbansal/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/Users/tusharbansal/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : nan\n",
      "Precision: nan\n",
      "Recall   : nan\n",
      "F1 Score : nan\n",
      "\n",
      "Detailed Classification Report:\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 0, does not match size of target_names, 28. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetailed Classification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m ordered_labels \u001b[38;5;241m=\u001b[39m [id2label[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(id2label\u001b[38;5;241m.\u001b[39mkeys(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)]\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\n\u001b[1;32m     13\u001b[0m     y_true,\n\u001b[1;32m     14\u001b[0m     y_pred,\n\u001b[1;32m     15\u001b[0m     target_names\u001b[38;5;241m=\u001b[39mordered_labels,\n\u001b[1;32m     16\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     17\u001b[0m ))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2970\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2964\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2965\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2966\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2967\u001b[0m             )\n\u001b[1;32m   2968\u001b[0m         )\n\u001b[1;32m   2969\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2970\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2971\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2972\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2973\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2974\u001b[0m         )\n\u001b[1;32m   2975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2976\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 0, does not match size of target_names, 28. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "y_true = val_df[\"main_label\"].astype(int).to_numpy()\n",
    "y_pred = val_df[\"predicted_id\"].astype(int).to_numpy()\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "print(\"Recall   :\", recall_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "print(\"F1 Score :\", f1_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\\n\")\n",
    "\n",
    "ordered_labels = [id2label[i] for i in sorted(id2label.keys(), key=int)]\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=ordered_labels,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7a6ade1-0d25-4d58-877c-b3af99632f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['content', 'labels', 'id', 'predicted_id', 'predicted_label', 'main_label']\n",
      "‚úÖ Remaining samples after cleanup: 0\n",
      "‚ö†Ô∏è No samples available for evaluation ‚Äî check earlier prediction step.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Rebuild main_label safely\n",
    "if \"main_label\" not in val_df.columns and \"labels\" in val_df.columns:\n",
    "    val_df[\"main_label\"] = val_df[\"labels\"].apply(\n",
    "        lambda x: int(x[0]) if isinstance(x, list) and len(x) > 0 else None\n",
    "    )\n",
    "\n",
    "# Check columns exist before proceeding\n",
    "cols = val_df.columns.tolist()\n",
    "print(\"Available columns:\", cols)\n",
    "\n",
    "# Keep only rows with valid ground truth + prediction\n",
    "val_df = val_df.dropna(subset=[\"main_label\", \"predicted_id\"], how=\"any\")\n",
    "print(f\"‚úÖ Remaining samples after cleanup: {len(val_df)}\")\n",
    "\n",
    "if len(val_df) == 0:\n",
    "    print(\"‚ö†Ô∏è No samples available for evaluation ‚Äî check earlier prediction step.\")\n",
    "else:\n",
    "    y_true = val_df[\"main_label\"].astype(int).to_numpy()\n",
    "    y_pred = val_df[\"predicted_id\"].astype(int).to_numpy()\n",
    "\n",
    "    print(f\"üßÆ Evaluating on {len(y_true)} samples...\")\n",
    "\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "\n",
    "    print(\"\\nDetailed Classification Report:\\n\")\n",
    "\n",
    "    id2label = model.config.id2label\n",
    "    available_classes = sorted(set(y_true) & set(y_pred))\n",
    "    ordered_labels = [id2label[i] for i in available_classes]\n",
    "\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            labels=available_classes,\n",
    "            target_names=ordered_labels,\n",
    "            zero_division=0\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c35bdc-69aa-455e-8a81-a5f4972b6349",
   "metadata": {},
   "source": [
    "The following cells above had the use of pre-trained model of Roberta on the GoEmotions dataset which had 28 classes. The model when tested using a held-out validation dataset provided a good accuracy metrics overall. \n",
    "\n",
    "But, I will try and fine-tune this model now to see if I can improve the accuracy of this model any better or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa169a26-6051-41ef-b311-d5847e5aaea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486fb3d0cc0144c8aca1c9eaad05295d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34728 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76d3e10e51244f49be3b3d1d3770098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8682 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas ‚Üí Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"content\", \"main_label\"]])\n",
    "val_dataset   = Dataset.from_pandas(val_df[[\"content\", \"main_label\"]])\n",
    "\n",
    "# Tokenisation function\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"content\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Apply tokenisation\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset   = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Rename columns for Trainer compatibility\n",
    "train_dataset = train_dataset.rename_column(\"main_label\", \"labels\")\n",
    "val_dataset   = val_dataset.rename_column(\"main_label\", \"labels\")\n",
    "\n",
    "# Keep only required columns\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b3bac30-1975-4b5a-a963-c7e2ade51666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds  = np.argmax(pred.predictions, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1  = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b407eb9f-108a-456b-99a5-669ea5a98e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW \n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Optimiser\n",
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e5c7da9-6171-4e81-9748-a1214cd21439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed90ec63843b42a494a72a04590edbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/4341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 training loss: 1.0543\n",
      "Validation Accuracy: 0.6730 | F1: 0.6754\n",
      "‚ö†Ô∏è No improvement this epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cae13fc5ad465b9dde332c405f12fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/4341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 training loss: 0.8723\n",
      "Validation Accuracy: 0.6835 | F1: 0.6796\n",
      "‚ö†Ô∏è No improvement this epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abcb2648d3c494cb295d4678f245349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/4341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 training loss: 0.7002\n",
      "Validation Accuracy: 0.6697 | F1: 0.6664\n",
      "‚ö†Ô∏è No improvement this epoch.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()   # üëà single-label loss\n",
    "\n",
    "best_f1 = 0.73\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        optim.zero_grad()\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        labels = inputs.pop(\"labels\")             # remove labels from inputs\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits                   # [batch, 28]\n",
    "        loss = criterion(logits, labels)          # ‚úÖ works with single int labels\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1} training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    preds_all, labels_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            preds_all.extend(preds)\n",
    "            labels_all.extend(labels)\n",
    "\n",
    "    acc = accuracy_score(labels_all, preds_all)\n",
    "    f1  = f1_score(labels_all, preds_all, average=\"weighted\")\n",
    "    print(f\"Validation Accuracy: {acc:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        model.save_pretrained(\"./roberta_goemotions_best_manual\")\n",
    "        tokenizer.save_pretrained(\"./roberta_goemotions_best_manual\")\n",
    "        print(f\"üíæ Model improved ‚Üí saved (F1={best_f1:.4f})\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No improvement this epoch.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
